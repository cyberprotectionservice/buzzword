# .env example for deploying buzzword
# comment out keys you are not using

# corpora file, which tells the tool which corpora to load, and provides metadata
BUZZWORD_CORPORA_FILE=corpora.json
# directory in which buzzword will save uploaded corpora, csvs, etc
BUZZWORD_ROOT=./
# run flask/dash app in debug mode
BUZZWORD_DEBUG=true
# how many results per datatable (unused while tables are virtualised)
BUZZWORD_PAGE_SIZE=25
# maximum table dimensions to display in data tables
BUZZWORD_TABLE_SIZE=2000,200  # rows,columns
# Global corpus settings each can be overwritten per corpus in corpora.json
# load corpora into memory 
BUZZWORD_LOAD=true
# cut datasets to this many rows (useful for very large datasets)
BUZZWORD_MAX_DATASET_ROWS=99999
# columns to drop before loading dataset into buzzword
BUZZWORD_DROP_COLUMNS=parse,text
# add governor features to corpora. this allows searching/showing governor token,
# but doubles the loading time on startup, and might slow things down a little
BUZZWORD_ADD_GOVERNOR=false
# preload explore for every corpus?
BUZZWORD_LOAD_LAYOUTS=true
# max number of concordance lines generated --- they can be slow, esp on large corpora
BUZZWORD_MAX_CONC=999
# path to tesseract data -- needed to get correct OCR models for PDF corpora
TESSDATA_PREFIX=tessdata
