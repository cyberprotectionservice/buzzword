{
    "intro": "# Swiss law corpus: a sample investigation\n\nThe corpus being investigated is comprised of three books, which have undergone optical character recognition (OCR) via tesseract and parsing via buzz/spaCy.\n\nThe original texts are typset with Fraktur fonts, making the accuracy of OCR far from perfect. In turn, this effects parser accuracy, and thus, it can be expected that no frequency counting will be perfectly accurate.\n\nTo address this, we built the [compare interface](/compare), which allows registered users to edit the results of the OCR process, and also to add annotations in the form of XML tags, which can later be used in the analysis process. Changes made to the OCR are not instantly reflected in the analysis interface; this update is performed manually, following review of submitted corrections.\n\nThe analysis presented here will therefore improve when re-run on increasingly correct versions of the OCR text.\n\nThe first part of this sample analysis is to simply perform a broad 'distant reading' of the texts, in order to provide a context that will aid us in answering a more specific research question: *xxx*.\n\nFirst, we remove non-words from our text. This would not be necessary with a perfect corpus; however, the OCR process results in a number of non-words entering the corpus (for example, from marks and blemishes on the original page). In the analysis interface, this translates to searching for words that match the regular expression `[A-Za-z]{2,}` (i.e., any word containing at least two alphabetical characters in a row).",
    "freq": "## Word frequencies\n\nHere we can count the relative frequency of common nounsHere we can count the relative frequency of common nounsHere we can count the relative frequency of common nounsHere we can count the relative frequency of common nounsHere we can count the relative frequency of common nounsHere we can count the relative frequency of common nounsHere we can count the relative frequency of common nounsHere we can count the relative frequency of common nounsHere we can count the relative frequency of common nouns by the year of the text. Here we can count the relative frequency of common nouns by the year of the text. Here we can count the relative frequency of common nouns by the year of the text. Here we can count the relative frequency of common nouns by the year of the text. Here we can count the relative frequency of common nouns by the year of the text. Here we can count the relative frequency of common nouns by the year of the text.",
    "calc": "## Finding keywords\n\nSo far, we have located some words of interest. For a next step, we can calculate the keyness of these words---that is, the extent to which these words are particularly common in this corpus, when compared to German language used generally. To do this, we rely on a word frequency list of the most common German words, in this case, extracted from a large database of film and television subtitles. Of course, preferable would be to have a more closely related reference dataset (i.e. of other legal texts, or other texts from the time, but without such data readily available, this more general resource will sufice for now.",
    "vis": "## Visualising frequencies\n\nWith the data generated above, we can generate interactiWith the data generated above, we can generate interactiWith the data generated above, we can generate interactiWith the data generated above, we can generate interactiWith the data generated above, we can generate interactiWith the data generated above, we can generate interactiWith the data generated above, we can generate interactiWith the data generated above, we can generate interactiWith the data generated above, we can generate interactiWith the data generated above, we can generate interactiWith the data generated above, we can generate interactiWith the data generated above, we can generate interactiWith the data generated above, we can generate interactive visualisations that help us in the distant reading process. Let's try viewing our keywords as a stacked bar, and as a heatmap. You can generate charts of your own using the table data as well, if you like!",
    "conc": "## Concordancing\n\nConcordancing, sometimes called *Keyword in context (KWIC)*, allows you to quickly see each instance of a word, and what occurs alongside it. You can search for anything you like in the space below. However, for more advanced functionality, you should use the dedicated [explore interface](/explore).",
    "end": "## Where to from here?\n\nThat's as far as this investigation goes, for now. Hopefully, this is enough to show you how to construct a workflow using *buzzword* and the Swiss Digital Law Discovery Corpus."
}
